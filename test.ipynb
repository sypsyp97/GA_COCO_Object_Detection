{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import scipy.io\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T21:16:42.872090Z",
     "end_time": "2023-04-23T21:16:42.915775Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Path to images and annotations\n",
    "path_images = \"101_ObjectCategories/airplanes/\"\n",
    "path_annot = \"Annotations/Airplanes_Side_2/\"\n",
    "\n",
    "\n",
    "# list of paths to images and annotations\n",
    "image_paths = [\n",
    "    f for f in os.listdir(path_images) if os.path.isfile(os.path.join(path_images, f))\n",
    "]\n",
    "annot_paths = [\n",
    "    f for f in os.listdir(path_annot) if os.path.isfile(os.path.join(path_annot, f))\n",
    "]\n",
    "\n",
    "image_paths.sort()\n",
    "annot_paths.sort()\n",
    "\n",
    "image_size = 224  # resize input images to this size\n",
    "\n",
    "images, targets = [], []\n",
    "\n",
    "# loop over the annotations and images, preprocess them and store in lists\n",
    "for i in range(0, len(annot_paths)):\n",
    "    # Access bounding box coordinates\n",
    "    annot = scipy.io.loadmat(path_annot + annot_paths[i])[\"box_coord\"][0]\n",
    "\n",
    "    top_left_x, top_left_y = annot[2], annot[0]\n",
    "    bottom_right_x, bottom_right_y = annot[3], annot[1]\n",
    "\n",
    "    image = keras.utils.load_img(\n",
    "        path_images + image_paths[i],\n",
    "    )\n",
    "    (w, h) = image.size[:2]\n",
    "\n",
    "    # resize train set images\n",
    "    # if i < int(len(annot_paths) * 0.8):\n",
    "        # resize image if it is for training dataset\n",
    "    image = image.resize((image_size, image_size))\n",
    "\n",
    "    # convert image to array and append to list\n",
    "    images.append(keras.utils.img_to_array(image))\n",
    "\n",
    "    # apply relative scaling to bounding boxes as per given image and append to list\n",
    "    targets.append(\n",
    "        (\n",
    "            float(top_left_x) / w,\n",
    "            float(top_left_y) / h,\n",
    "            float(bottom_right_x) / w,\n",
    "            float(bottom_right_y) / h,\n",
    "        )\n",
    "    )\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T21:18:47.640815Z",
     "end_time": "2023-04-23T21:18:48.588597Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "(x_train), (y_train) = (\n",
    "    np.asarray(images[: int(len(images) * 0.8)]),\n",
    "    np.asarray(targets[: int(len(targets) * 0.8)]),\n",
    ")\n",
    "\n",
    "(x_test), (y_test) = (\n",
    "    np.asarray(images[int(len(images) * 0.8) :]),\n",
    "    np.asarray(targets[int(len(targets) * 0.8) :]),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T21:21:30.856667Z",
     "end_time": "2023-04-23T21:21:30.934165Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def conv_block(x, filters=16, kernel_size=3, strides=2):\n",
    "    conv_layer = layers.Conv2D(filters, kernel_size, strides=strides, activation=tf.nn.swish, use_bias=False, padding=\"same\", groups=1)\n",
    "\n",
    "    return conv_layer(x)\n",
    "\n",
    "\n",
    "def inverted_residual_block(x, expanded_channels, output_channels, strides=1):\n",
    "    m = layers.Conv2D(expanded_channels, 1, padding=\"same\", use_bias=False, groups=1)(x)\n",
    "    m = layers.BatchNormalization()(m)\n",
    "\n",
    "    m = layers.DepthwiseConv2D(3, strides=strides, padding=\"same\", use_bias=False)(m)\n",
    "    m = layers.BatchNormalization()(m)\n",
    "    m = tf.nn.swish(m)\n",
    "\n",
    "    m = layers.Conv2D(output_channels, 1, padding=\"same\", use_bias=False, groups=1)(m)\n",
    "    m = layers.BatchNormalization()(m)\n",
    "\n",
    "    if strides == 1:\n",
    "        return layers.Concatenate(axis=-1)([m, x])\n",
    "    elif strides == 2:\n",
    "        x = layers.Conv2D(output_channels, kernel_size=(2, 2), strides=2, padding=\"same\", groups=1)(x)\n",
    "        return layers.Concatenate(axis=-1)([m, x])\n",
    "\n",
    "    return m\n",
    "\n",
    "\n",
    "def ffn(x, hidden_units, dropout_rate, use_bias=False):\n",
    "    a = tf.reshape(x, (-1, 1, x.shape[1], x.shape[-1]))\n",
    "\n",
    "    for hidden_unit in hidden_units:\n",
    "        a = tf.keras.layers.Conv2D(filters=hidden_unit, kernel_size=1, activation=tf.nn.swish, padding='same', use_bias=use_bias, groups=1)(a)\n",
    "        a = layers.Dropout(dropout_rate)(a)\n",
    "\n",
    "    x = tf.reshape(a, (-1, x.shape[1], x.shape[-1]))\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def transformer_block(x, transformer_layers, projection_dim, num_heads=2):\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(x)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=projection_dim, dropout=0.0, use_bias=False)(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, x])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        # x3 = mlp(x3, hidden_units=[x.shape[-1] * 2, x.shape[-1]], dropout_rate=0.1,)\n",
    "        x3 = ffn(x3, hidden_units=[x.shape[-1] * 2, x.shape[-1]], dropout_rate=0.0,)\n",
    "        # Skip connection 2.\n",
    "        x = layers.Add()([x3, x2])\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def mobilevit_block(x, num_blocks, projection_dim, strides=1):\n",
    "    # Local projection with convolutions.\n",
    "    local_features = conv_block(x, filters=projection_dim, strides=strides)\n",
    "    local_features = conv_block(local_features, filters=projection_dim, kernel_size=1, strides=strides)\n",
    "\n",
    "    non_overlapping_patches = tf.reshape(local_features, (-1, tf.shape(local_features)[1] * tf.shape(local_features)[2], tf.shape(local_features)[-1]))\n",
    "\n",
    "    global_features = transformer_block(non_overlapping_patches, num_blocks, projection_dim)\n",
    "\n",
    "    folded_feature_map = tf.reshape(global_features, (-1, tf.shape(local_features)[1], tf.shape(local_features)[2], tf.shape(local_features)[-1]))\n",
    "\n",
    "\n",
    "    # Apply point-wise conv -> concatenate with the input features.\n",
    "    folded_feature_map = conv_block(folded_feature_map, filters=x.shape[-1], kernel_size=1, strides=strides)\n",
    "    local_global_features = layers.Concatenate(axis=-1)([x, folded_feature_map])\n",
    "\n",
    "    # Fuse the local and global features using a convolution layer.\n",
    "    local_global_features = conv_block(local_global_features, filters=projection_dim, strides=strides)\n",
    "\n",
    "    return local_global_features\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T21:23:20.560827Z",
     "end_time": "2023-04-23T21:23:20.607643Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def create_mobilevit(num_classes=4, expansion_factor=2, image_size=224):\n",
    "\n",
    "    inputs = keras.Input((image_size, image_size, 3))\n",
    "    x = layers.Rescaling(scale=1.0 / 255)(inputs)\n",
    "\n",
    "    # Initial conv-stem -> MV2 block.\n",
    "    x = layers.Conv2D(filters=16, kernel_size=16, strides=16, activation=tf.nn.swish, use_bias=False, padding=\"same\")(x)\n",
    "    x = inverted_residual_block(x, expanded_channels=16 * expansion_factor, output_channels=16)\n",
    "\n",
    "    # Downsampling with MV2 block.\n",
    "    x = inverted_residual_block(x, expanded_channels=16 * expansion_factor, output_channels=24, strides=2)\n",
    "    x = inverted_residual_block(x, expanded_channels=24 * expansion_factor, output_channels=24)\n",
    "    x = inverted_residual_block(x, expanded_channels=24 * expansion_factor, output_channels=24)\n",
    "\n",
    "    # First MV2 -> MobileViT block.\n",
    "    x = inverted_residual_block(x, expanded_channels=24 * expansion_factor, output_channels=48, strides=2)\n",
    "    x = mobilevit_block(x, num_blocks=2, projection_dim=64)\n",
    "\n",
    "    # Second MV2 -> MobileViT block.\n",
    "    x = inverted_residual_block(x, expanded_channels=64 * expansion_factor, output_channels=64, strides=2)\n",
    "    x = mobilevit_block(x, num_blocks=4, projection_dim=80)\n",
    "\n",
    "    # Third MV2 -> MobileViT block.\n",
    "    x = inverted_residual_block(x, expanded_channels=80 * expansion_factor, output_channels=80, strides=2)\n",
    "    x = mobilevit_block(x, num_blocks=3, projection_dim=96)\n",
    "    x = conv_block(x, filters=320, kernel_size=1, strides=1)\n",
    "    # Classification head.\n",
    "    x = layers.GlobalAvgPool2D()(x)\n",
    "    bounding_box = layers.Dense(num_classes)(x)\n",
    "\n",
    "    model = keras.Model(inputs, bounding_box)\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T21:23:21.455199Z",
     "end_time": "2023-04-23T21:23:21.457970Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class MeanIoU(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name=\"mean_iou\", **kwargs):\n",
    "        super(MeanIoU, self).__init__(name=name, **kwargs)\n",
    "        self.intersection = self.add_weight(name=\"intersection\", initializer=\"zeros\")\n",
    "        self.union = self.add_weight(name=\"union\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "\n",
    "        # Get the intersection coordinates of the bounding boxes\n",
    "        top_left = tf.maximum(y_true[:, :2], y_pred[:, :2])\n",
    "        bottom_right = tf.minimum(y_true[:, 2:], y_pred[:, 2:])\n",
    "\n",
    "        # Compute the intersection area\n",
    "        intersection_dims = tf.maximum(bottom_right - top_left, 0)\n",
    "        intersection_area = intersection_dims[:, 0] * intersection_dims[:, 1]\n",
    "\n",
    "        # Compute the area of the ground truth and predicted bounding boxes\n",
    "        y_true_area = (y_true[:, 2] - y_true[:, 0]) * (y_true[:, 3] - y_true[:, 1])\n",
    "        y_pred_area = (y_pred[:, 2] - y_pred[:, 0]) * (y_pred[:, 3] - y_pred[:, 1])\n",
    "\n",
    "        # Compute the union area\n",
    "        union_area = y_true_area + y_pred_area - intersection_area\n",
    "\n",
    "        # Update the intersection and union sums\n",
    "        self.intersection.assign_add(tf.reduce_sum(intersection_area))\n",
    "        self.union.assign_add(tf.reduce_sum(union_area))\n",
    "\n",
    "    def result(self):\n",
    "        return self.intersection / (self.union + tf.keras.backend.epsilon())\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.intersection.assign(0)\n",
    "        self.union.assign(0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T21:23:22.100536Z",
     "end_time": "2023-04-23T21:23:22.105984Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-23 21:26:14.863850: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:417] Loaded runtime CuDNN library: 8.1.1 but source was compiled with: 8.6.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.\n",
      "2023-04-23 21:26:14.864474: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at conv_ops.cc:1068 : UNIMPLEMENTED: DNN library is not found.\n",
      "2023-04-23 21:26:14.864492: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): UNIMPLEMENTED: DNN library is not found.\n",
      "\t [[{{node model_1/conv2d_50/Conv2D}}]]\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_1/conv2d_50/Conv2D' defined at (most recent call last):\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_43039/2876309752.py\", line 42, in <module>\n      history = run_experiment(\n    File \"/tmp/ipykernel_43039/2876309752.py\", line 18, in run_experiment\n      history = model.fit(\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 290, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 262, in convolution_op\n      return tf.nn.convolution(\nNode: 'model_1/conv2d_50/Conv2D'\nDNN library is not found.\n\t [[{{node model_1/conv2d_50/Conv2D}}]] [Op:__inference_train_function_35031]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnimplementedError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 42\u001B[0m\n\u001B[1;32m     40\u001B[0m vit_object_detector \u001B[38;5;241m=\u001B[39m create_mobilevit(num_classes\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m, expansion_factor\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# Train model\u001B[39;00m\n\u001B[0;32m---> 42\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mrun_experiment\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvit_object_detector\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[16], line 18\u001B[0m, in \u001B[0;36mrun_experiment\u001B[0;34m(model, learning_rate, weight_decay, batch_size, num_epochs)\u001B[0m\n\u001B[1;32m     10\u001B[0m checkpoint_filepath \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcheckpoints\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     11\u001B[0m checkpoint_callback \u001B[38;5;241m=\u001B[39m keras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mModelCheckpoint(\n\u001B[1;32m     12\u001B[0m     checkpoint_filepath,\n\u001B[1;32m     13\u001B[0m     monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_mean_iou\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     14\u001B[0m     save_best_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     15\u001B[0m     save_weights_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m     16\u001B[0m )\n\u001B[0;32m---> 18\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m    \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     20\u001B[0m \u001B[43m    \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     22\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcheckpoint_callback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m        \u001B[49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEarlyStopping\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmonitor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mval_loss\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpatience\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[43m    \u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m history\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[1;32m     53\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mUnimplementedError\u001B[0m: Graph execution error:\n\nDetected at node 'model_1/conv2d_50/Conv2D' defined at (most recent call last):\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_43039/2876309752.py\", line 42, in <module>\n      history = run_experiment(\n    File \"/tmp/ipykernel_43039/2876309752.py\", line 18, in run_experiment\n      history = model.fit(\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 290, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"/home/yipeng/miniconda3/envs/tf/lib/python3.9/site-packages/keras/layers/convolutional/base_conv.py\", line 262, in convolution_op\n      return tf.nn.convolution(\nNode: 'model_1/conv2d_50/Conv2D'\nDNN library is not found.\n\t [[{{node model_1/conv2d_50/Conv2D}}]] [Op:__inference_train_function_35031]"
     ]
    }
   ],
   "source": [
    "def run_experiment(model, learning_rate, weight_decay, batch_size, num_epochs):\n",
    "\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    # Compile model.\n",
    "    model.compile(optimizer=optimizer, loss=keras.losses.MeanSquaredError(), metrics=[MeanIoU()])\n",
    "\n",
    "    checkpoint_filepath = \"checkpoints\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_mean_iou\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[\n",
    "            checkpoint_callback,\n",
    "            keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=20),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return history\n",
    "\n",
    "\n",
    "input_shape = (image_size, image_size, 3)  # input image shape\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 32\n",
    "num_epochs = 100\n",
    "\n",
    "\n",
    "vit_object_detector = create_mobilevit(num_classes=4, expansion_factor=2)\n",
    "# Train model\n",
    "history = run_experiment(\n",
    "    vit_object_detector, learning_rate, weight_decay, batch_size, num_epochs\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
